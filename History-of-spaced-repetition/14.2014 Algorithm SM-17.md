# 2014: Algorithm SM-17

[TOC=2,5]

# 2014算法 SM-17

The newest [SuperMemo](https://supermemo.guru/wiki/SuperMemo) algorithm in its design can be used to summarize its own phylogeny. It can also be used to write the counterfactual history of [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition). If there were no dinosaurs, humans might not have emerged or might look differently. However, the entire dino branch of the evolutionary tree could easily be chopped off, and still keep humans safe on their own mammalian branch.

In a similar fashion, we can show a seemingly deterministic chain of linked events in the emergence of [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition) and [Algorithm SM-17](https://supermemo.guru/wiki/Algorithm_SM-17). This can be used to prove that [Biedalak](https://supermemo.guru/wiki/Biedalak) or [Murakowski](https://supermemo.guru/wiki/Murakowski) were more important for history of [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition) than [Ebbinghaus](https://supermemo.guru/wiki/Ebbinghaus). Anki was more important than Pimsleur. [Gary Wolf](https://supermemo.guru/wiki/Gary_Wolf) provided more impact than William James.

最新的[SuperMemo](https://supermemo.guru/wiki/SuperMemo)算法可以用来总结自己的发展史。它也可以用来记录[间隔重复](https://supermemo.guru/wiki/Spaced_repetition)的反事实历史。如果没有恐龙，人类可能就不会出现，或者看起来会不一样。然而，进化树上的整个恐龙分支很容易被砍掉，而人类仍然可以安全地生活在自己的哺乳动物分支上。

以类似的方式，我们可以在[间隔重复](https://supermemo.guru/wiki/Spaced_repetition)和[算法SM-17](https://supermemo.guru/wiki/Algorithm_SM-17)的出现中，显示一个看似确定的链接事件链。这可以用来证明[Biedalak](https://supermemo.guru/wiki/Biedalak)或[Murakowski](https://supermemo.guru/wiki/Murakowski)更重要的历史[记忆](https://supermemo.guru/wiki/Spaced_repetition)比[艾宾浩斯](https://supermemo.guru/wiki/Ebbinghaus)。安奇比皮姆斯勒更重要。[加里·沃尔夫](https://supermemo.guru/wiki/Gary_Wolf)比威廉·詹姆斯更有影响力。

However, the maximum impact of [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition) is yet to be seen and confluence of forces may re-arrange those early influences. In particular, with an explosion in legitimate competition, the central role of [SuperMemo](https://supermemo.guru/wiki/SuperMemo) can only be retained with further innovation (e.g. see [neural creativity](https://supermemo.guru/wiki/Neural_creativity)).

然而，[间隔重复](https://supermemo.guru/wiki/Spaced_repetition)的最大影响还有待观察，力量的汇合可能重新安排这些早期影响。特别是，随着合法竞争的激增，[SuperMemo](https://supermemo.guru/wiki/SuperMemo)的核心地位只能通过进一步的创新(例如，参见[neural creativity](https://supermemo.guru/wiki/Neural_creativity)来保持。

Here is how I would explain the entire [Algorithm SM-17](https://supermemo.guru/wiki/Algorithm_SM-17) using the building blocks of history as written for this article:

- the key to long-term retention is to [compute optimum spacing](https://supermemo.guru/wiki/The_birthday_of_spaced_repetition:_July_31,_1985) (1985)
- as spacing depends on [memory complexity](https://supermemo.guru/wiki/Memory_complexity), we need to begin with classifying [items](https://supermemo.guru/wiki/Item) into [difficulty](https://supermemo.guru/wiki/SuperMemo_1.0_for_DOS_(1987)) categories (1987)
- we find the optimum review time by [plotting the forgetting curve](https://supermemo.guru/wiki/Employing_forgetting_curves_in_spaced_repetition_(1991)), which indicates a moment when [retention](https://supermemo.guru/wiki/Retention) drops below an acceptable level (1991)
- to find optimum time in scarce data, we need to use approximations, and it helps to know that [forgetting is exponential](https://supermemo.guru/wiki/Exponential_nature_of_forgetting) (1994)
- as the speed of [forgetting](https://supermemo.guru/wiki/Forgetting) depends on [memory stability](https://supermemo.guru/wiki/Memory_stability), the whole algorithm must be designed with [two component of memory](https://supermemo.guru/wiki/Two_components_of_memory) at its core (1988). The lack of consideration for the model may be the chief mistake made by developers of competitive [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition) algorithms, e.g. as in the case of the [neural network approach](https://supermemo.guru/wiki/Neural_networks_in_spaced_repetition) (1997)
- the key power of the two components model is to make it possible to [compute the increase in memory stability at review](https://supermemo.guru/wiki/SuperMemo_Algorithm:_30-year-long_labor) (2005)
- the algorithm must build the model of memory by collecting repetition data. It must be [adaptable to the available information](https://supermemo.guru/wiki/First_adaptable_spaced_repetition_algorithm:_Algorithm_SM-4) (1989)
- before data is available, it is helpful to start with a [universal memory formula](https://supermemo.guru/wiki/Search_for_a_universal_memory_formula) (1990)
- further minor adjustments and improvements can make [a world of difference](https://supermemo.guru/wiki/First_data-driven_spaced_repetition_algorithm:_Algorithm_SM-8) (1995), e.g. post-lapse interval, [absolute difficulty](https://supermemo.guru/wiki/A-Factor), fast multi-dimensional regression, etc.
- [universal metric](https://supermemo.guru/wiki/Universal_metric) is needed to fine-tune optimization parameters in future algorithms (2018)

以下是我将如何解释整个[算法SM-17](https://supermemo.guru/wiki/Algorithm_SM-17)使用为本文编写的历史构建块:



- 长期记忆的关键是[计算最佳间隔](https://supermemo.guru/wiki/The_birthday_of_spaced_repetition:_July_31，_1985) (1985)

- 由于间距取决于[内存复杂度](https://supermemo.guru/wiki/memory_复杂性)，我们需要开始分类[项目](https://supermemo.guru/wiki/Item)到[困难](https://supermemo.guru/wiki/SuperMemo_1.0_for_DOS_(1987))类别(1987)

- 我们通过[绘制遗忘曲线](https://supermemo.guru/wiki/Employing_forgetting_curves_in_spaced_repetition_(1991))找到最佳的复习时间，这表明[retention](https://supermemo.guru/wiki/Retention)下降到一个可接受的水平(1991)。

- 为了在稀缺的数据中找到最佳时间，我们需要使用近似法，这有助于了解[遗忘是指数级的](https://supermemo.guru/wiki/exponential_nature_of_forget) (1994)

- [遗忘](https://supermemo.guru/wiki/Forgetting)的速度取决于[记忆稳定性](https://supermemo.guru/wiki/Memory_stability),整个算法必须设计[两个组件的内存](https://supermemo.guru/wiki/Two_components_of_memory)的核心(1988)。缺乏考虑的模型可能是竞争的主要开发人员所犯的错误[记忆](https://supermemo.guru/wiki/Spaced_repetition)算法,如如的情况下[神经网络方法](https://supermemo.guru/wiki/Neural_networks_in_spaced_repetition) (1997)

- 两个组件模型的关键功能是使[在评审时计算增加的内存稳定性](https://supermemo.guru/wiki/SuperMemo_Algorithm:_30-year-long_labor) 成为可能(2005)

- 算法必须通过收集重复数据来建立内存模型(https://supermemo.guru/wiki/First_adaptable_spaced_repetition_algorithm: _algorithm_mc -4) (1989)

- 在数据可用之前，最好从一个[通用内存公式](https://supermemo.guru/wiki/Search_for_a_universal_memory_formula) 开始(1990)

- 进一步的细微调整和改进可以使[a world of difference](https://supermemo.guru/wiki/First_data-driven_spaced_repetition_algorithm: _algorithm_mc -8)(1995)，例如后距间隔，[绝对难度](https://supermemo.guru/wiki/A-Factor)，快速多维回归等。

- [universal metric](https://supermemo.guru/wiki/Universal_metric)需要在未来的算法中对优化参数进行微调(2018)

And so, step by step, [Algorithm SM-17](https://supermemo.guru/wiki/Algorithm_SM-17) has emerged at the top of the evolutionary tree in [spaced repetition](https://supermemo.guru/wiki/Spaced_repetition).